<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Resampling Methods</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.19/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uwm-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Resampling Methods
]

---


&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 22px;
    padding: 1em 4em 1em 4em;
}
&lt;/style&gt;




## Last time...

### Review Lecture

* Reviewed Logistic Regression
* Went over Weighted Least Squares (WLS)
* Discussed Random R Things

--

## Today

* Start looking at topics related to machine learning
* We are going to start off with __Resampling methods__

---
## First. Sampling

It is impossible to survey every person in the population we are interested in, so we often take a "random sample" from the population and calculate a **sample statistic** (e.g., mean, median). 

--

A lot of our statistics follow well-defined distributions (e.g., normal distribution), and we use the properties of these distributions to estimate the population parameter. 

---
## Problems with Sampling

### Single Estimate of the Population Parameter

- Estimate the population mean

- Sampling distribution of mean derived from sample statistics

- Built a 95% confidence interval around the sample mean

- We've been **relying on a single estimate** of the population parameter. 

--

### Assumptions

- We make assumptions about the sample (e.g., representative sample, large sample size, normality), which may or may not be true.

---
## Introduction to Resampling

A statistical technique that involves re-estimation of the population parameter by repeatedly drawing samples from **the original sample**

--

### Reasons for Resampling

- Reduce bias of the estimate by using multiple samples instead of one
  
- Better sense of precision of the estimated population parameter
  
- We do not need to make assumptions about the population distribution (e.g., when we perform two samples t-test, for example, we make the assumption that the populations from which the samples are drawn are normally distributed)
  
- Sample does not have to be large

---
## Types of Resampling

- Bootstrapping

- Jackknife method (just a glimpse)

- Permutation testing (just a glimpse; Research Methods will cover it)

---
## Bootstrapping

The term **bootstrapping** comes from the expression "pull oneself up by one's bootstraps" which means to "to help oneself without the aid of others; use one's resources". 

--

**Bootstrapping** is a method where we rely entirely on the sample that we have at hand. We randomly sample within the sample (with replacement) and compute the estimator of interest to build an empirical distribution of that test statistic.

---
### Illustration of Bootstrapping

Imagine we are trying to estimate the height of a class cohort and have a representative sample consisting of (just) 6 people: April, Beatrice, Carl, David, Emily, and Frank. 

To estimate their height, you decide to perform bootstrapping, meaning you draw many samples from this group of 6 people, *with replacement*, each time calculating the average height of the sample.

--


```
## [1] "David"    "Beatrice" "Beatrice" "April"    "Frank"    "April"
```

```
## [1] "Mean height of this sample: 167.166666666667"
```

### We notice that:

--

The number of students that we randomly sample is 6, the same number of students inside the initial sample. 

--

Within the same sample, there can be duplicate students (e.g., Emily). This is what it means to randomly sample **with replacement**. 

---
## Repeat


```
## [1] "Emily"    "David"    "Beatrice" "Emily"    "Beatrice" "Emily"
```

```
## [1] "Mean height of this sample: 169.333333333333"
```
--

```
## [1] "Frank"    "David"    "Emily"    "Emily"    "Emily"    "Beatrice"
```

```
## [1] "Mean height of this sample: 170.666666666667"
```
--

```
## [1] "Beatrice" "David"    "April"    "David"    "Emily"    "Carl"
```

```
## [1] "Mean height of this sample: 170"
```

---
### Bootstrap 10,000 Times


```r
# When resampling, it is generally a good practice to set random seed
# for full reproducibility of the resampling process
set.seed(1048596)

boot &lt;- 10000 # Set number of bootstrap samples

friends &lt;- c('April', 'Beatrice', 'Carl', 'David', 'Emily', 'Frank')
heights &lt;- c(165, 165, 178, 170, 172, 173)

sample_means &lt;- NULL # Initialize list to store sample means
```

---
### Bootstrap 10,000 Times


```r
# When resampling, it is generally a good practice to set random seed
# for full reproducibility of the resampling process
set.seed(1048596)

boot &lt;- 10000 # Set number of bootstrap samples

friends &lt;- c('April', 'Beatrice', 'Carl', 'David', 'Emily', 'Frank')
heights &lt;- c(165, 165, 178, 170, 172, 173)

sample_means &lt;- NULL # Initialize list to store sample means

# Append the mean of bootstrap sample heights to *sample_means*
*for(i in 1:boot){
* this_sample &lt;- sample(heights, size = length(heights), replace = T)
* sample_means &lt;- c(sample_means, mean(this_sample))
*} 
```

---
### Comparison

&lt;img src="bootstrapping_lecture_messi_files/figure-html/unnamed-chunk-8-1.png" width="720" /&gt;

---
## Another Example

Central tendency and variability of 216 response times. 

There are several candidates for central tendency (e.g., mean, median) and for variability (e.g., standard deviation, interquartile range). **Some of these do not have well understood theoretical sampling distributions.**

For the mean and standard deviation, we have theoretical sampling distributions to help us, provided we think the mean and standard deviation are the best indices. For the others, we can use bootstrapping.

--
### Simulate Response Time


```r
# Set random seed before generating data
set.seed(1048596)

# The observations generally follow the F Distribution + random noise
response = rf(n = 216, 3, 50) 
response = response * 500 + rnorm(n = 216, mean = 200, sd = 100)
```

---
### Visualize Data
&lt;img src="bootstrapping_lecture_messi_files/figure-html/unnamed-chunk-10-1.png" width="648" /&gt;

---
### Mean of Response Time


```r
set.seed(1048596) # Set random seed
boot &lt;- 10000 # Set number of bootstrap samples

response_means &lt;- NULL # Initialize list of mean values

for(i in 1:boot){
  sample_response &lt;- sample(response, size = 216, replace = T)
  response_means &lt;- c(response_means, mean(sample_response))
}
```

What is the bootstrap mean and its 95% CI?


```r
mean(response_means)
```

```
## [1] 682.3861
```

```r
quantile(response_means, probs = c(.025, .975))
```

```
##     2.5%    97.5% 
## 632.9458 732.5036
```

---

### Distribution of Means

&lt;img src="bootstrapping_lecture_messi_files/figure-html/unnamed-chunk-13-1.png" width="648" /&gt;

---
### Bootstrapped distribution of the median


```r
set.seed(1048596)
boot &lt;- 10000
response_med &lt;- NULL

for(i in 1:boot){
  sample_response &lt;- sample(response, size = 216, replace = T)
  response_med &lt;- c(response_med, median(sample_response))}
```
.pull-left[
&lt;img src="bootstrapping_lecture_messi_files/figure-html/unnamed-chunk-15-1.png" width="504" /&gt;
]
.pull-right[

```r
mean(response_med)
```

```
## [1] 599.7847
```

```r
median(response_med)
```

```
## [1] 598.9464
```

```r
quantile(response_med, 
         probs = c(.025, .975))
```

```
##     2.5%    97.5% 
## 542.4086 665.0578
```
]

---
### Bootstrapped distribution of the standard deviation


```r
set.seed(1048596)
boot &lt;- 10000
response_sd &lt;- NULL

for(i in 1:boot){
  sample_response &lt;- sample(response, size = 216, replace = T)
  response_sd &lt;- c(response_sd, sd(sample_response))}
```
.pull-left[
&lt;img src="bootstrapping_lecture_messi_files/figure-html/unnamed-chunk-18-1.png" width="504" /&gt;
]
.pull-right[

```r
mean(response_sd)
```

```
## [1] 374.9847
```

```r
median(response_sd)
```

```
## [1] 374.6161
```

```r
quantile(response_sd, 
         probs = c(.025, .975))
```

```
##     2.5%    97.5% 
## 326.0504 425.5348
```
]

---
### Other Estimators?

You can bootstrap estimates and 95% confidence intervals for *any* statistics you'll need to estimate. 

The `boot` package and function provides some help to speed this process along. Things you should learn how to do in R:

- learn to read a `for loop`
- learn to write your own function


```r
library(boot)

# function to obtain R-Squared from the data
rsq &lt;- function(data, indices) {
  d &lt;- data[indices,] # allows boot to select sample
  fit &lt;- lm(mpg ~ wt + disp, data = d) # this is the code you would have run
  return(summary(fit)$r.square)
}

results &lt;- boot(data = mtcars, statistic = rsq, R = 10000)
```

---
.pull-left[
&lt;img src="bootstrapping_lecture_messi_files/figure-html/unnamed-chunk-21-1.png" width="504" /&gt;
]

.pull-right[

```r
median(results$t)
```

```
## [1] 0.7962536
```

```r
boot.ci(results, type = "perc")
```

```
## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 10000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = results, type = "perc")
## 
## Intervals : 
## Level     Percentile     
## 95%   ( 0.6851,  0.8778 )  
## Calculations and Intervals on Original Scale
```
]

---
## Exercise 1 for the Day

In this district, Verizon provides line service to both Verizon and non-Verizon customers. Here, we are going to look at a dataset containing service waiting times for Verizon customers (ILEC) and non-Verizon customers (CLEC). We are interested in **whether waiting time of non-Verizon customers is longer than that of Verizon customers**. 

### Import Verizon Data


```r
Verizon = read.csv("https://raw.githubusercontent.com/shellyc26/psy5067/master/data/Verizon.csv")
```


```r
head(Verizon, 3)
```

```
##   Time Group
## 1 17.5  ILEC
## 2  2.4  ILEC
## 3  0.0  ILEC
```

---
### Inspect Verizon Data 1

&lt;img src="bootstrapping_lecture_messi_files/figure-html/unnamed-chunk-25-1.png" width="720" /&gt;

- Left is the distribution of waiting times of Non-Verizon (CLEC) customers; and
- Right is the distribution of waiting times of Verizon (ILEC) customers. 

--

You will notice: Both distributions are not normal.

---
### Inspect Verizon Data 2

&lt;img src="bootstrapping_lecture_messi_files/figure-html/unnamed-chunk-26-1.png" width="720" /&gt;

```
## 
## CLEC ILEC 
##   23 1664
```

--

You will notice: The groups are (very) unbalanced. 

---
### Analysis Plan and Justification 

It seems that the data does not meet the typical assumptions of an independent samples t-test. In this case, to estimate mean differences we can use bootstrapping. Here, we'll resample with replacement separately from the two samples and calculate their difference in means.

---
### Perhaps this will help:

```r
# Set random seed and number of bootstrap samples
set.seed(1048596)
boot &lt;- 10000

response_means &lt;- NULL

for(i in 1:boot){
  sample_response &lt;- sample(response, size = 216, replace = T)
  response_means &lt;- c(response_means,mean(sample_response))
}
```


### Breakdown of Tasks: Inside the For Loop

- Sample (with replacement) Verizon group (ILEC) customers

- Sample (with replacement) non-Verizon group (CLEC) customers

- Calculate the difference in means between the two groups

- Append the difference value to a list

--

---
### One Solution


```r
set.seed(1048596)
boot &lt;- 10000
difference &lt;- NULL

*subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
*subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")
```

---
### One Solution


```r
set.seed(1048596)
boot &lt;- 10000
difference &lt;- NULL

subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")

for(i in 1:boot){
  # Sample (with replacement) Verizon group (ILEC) customers
* sample_CLEC = sample(subsample_CLEC$Time,
*                      size = nrow(subsample_CLEC),
*                      replace = T)
  # Sample (with replacement) Non-Verizon group (CLEC) customers
* sample_ILEC = sample(subsample_ILEC$Time,
*                      size = nrow(subsample_ILEC),
*                      replace = T)
}
```

---
### One Solution


```r
set.seed(1048596)
boot &lt;- 10000
difference &lt;- NULL

subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")

for(i in 1:boot){
  # Sample (with replacement) Verizon group (ILEC) customers
  sample_CLEC = sample(subsample_CLEC$Time, 
                       size = nrow(subsample_CLEC), 
                       replace = T)
  # Sample (with replacement) Non-Verizon group (CLEC) customers
  sample_ILEC = sample(subsample_ILEC$Time, 
                       size = nrow(subsample_ILEC), 
                       replace = T)
  
  # Calculate the difference in means between the two groups
  # Append the difference value to a list
* difference &lt;- c(difference, mean(sample_CLEC) - mean(sample_ILEC))
}
```

---
### Bootstrap Distribution of Differences

&lt;img src="bootstrapping_lecture_messi_files/figure-html/unnamed-chunk-31-1.png" width="720" /&gt;

The difference in means is 7.84 `\([1.76,17.28]\)`. What would this mean?

--

The bootstrap CI does not include 0. This suggests that there is significant difference in the waiting time of Verizon and non-Verizon customers in the expected direction

---

### Bootstrapping Summary 1

Bootstrapping can be a useful tool to estimate parameters when 

--

1. You've violated assumptions of the test (i.e., normality, size of the sample)

--

2. You have good reason to believe the sampling distribution is not normal, but don't know what it is (e.g., median)

--

3. There are other oddities in your data, like very unbalanced samples 

--

This allows you to create a confidence interval around any statistic you want -- Cronbach's alpha, ICC, Mahalanobis Distance, `\(R^2\)`, AUC, etc. 
* You can test whether these statistics are significantly different from any other value. 

---

### Bootstrapping Summary 2

Bootstrapping will NOT help you deal with:

--

* Dependence between observations -- for this, you'll need to explicitly model dependence

--

* Improperly specified models or forms -- use theory to guide you here

--

* Measurement error -- why bother?

--

* Caveats: representativeness of the sample, outliers

---
## Jackknife Resampling

**Jackknife Resampling** is a method where researchers generate n sub-samples, each leaving out one observation. The method is very similar to bootstrapping except **the way that we create the sub-samples**.

---

### Illustration of Jackknife Resampling

Same example looking at cohort of 6 people: April, Beatrice, Carl, David, Emily, and Frank. If you decide to jackknife their heights, you would draw six sub-samples and calculate their respective mean height.


```r
friends = c('April', 'Beatrice', 'Carl', 'David', 'Emily', 'Frank')
heights = c(165, 165, 178, 170, 172, 173)
names(heights) = friends
```
--

```
## [1] "First Sub-sample:  Beatrice, Carl, David, Emily, Frank"
```
--

```
## [1] "Second Sub-sample:  April, Carl, David, Emily, Frank"
```
--

```
## [1] "Third Sub-sample:  April, Beatrice, David, Emily, Frank"
```
--

```
## [1] "Fourth Sub-sample:  April, Beatrice, Carl, Emily, Frank"
```
--

```
## [1] "Fifth Sub-sample:  April, Beatrice, Carl, David, Frank"
```
--

```
## [1] "Sixth Sub-sample:  April, Beatrice, Carl, David, Emily"
```

Notice that there are **6** sub-samples of **size 5**. 

---
## Jackknife Summary
1. Can be a useful way to assess the accuracy of a statistical estimator without making assumptions about the underlying distribution of the data. 

2. Generally, computationally efficient compared to bootstrapping because only *n* sub-samples are generated (compared to 10,000 for example)

3. Not used as much these days as bootstrapping can be used to perform the same task and more others. With advances in computing, bootstrapping is not as computationally intensive anymore.

--

## Limitations of Jackknife

* Sensitive to sample size: If sample size is small, it can result in inaccurate estimates of the bias (e.g., sample size of 6 means six jackknife samples).

---

## Exercise 2 for the Day

Again, we are going to look at a dataset containing service waiting time of Verizon customers (ILEC). We are going to use Jackknife Resampling to Estimate **the standard deviation of mean service waiting times** of Verizon Customers. 

--

### Access to Data:


```r
Verizon = read.csv("https://raw.githubusercontent.com/shellyc26/psy5067/master/data/Verizon.csv")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC") 
```

### Analysis Plan

* Create **n** subsamples, each leaving out the **n**th observation

* Calculate the mean and append it to a list

* Then calculate the standard deviation of the list

---

### One Way to do this


```r
# Initialize list to store sample means
sample_mean &lt;- NULL

# Append the mean of bootstrap sample heights to *sample_means*
for(i in 1:nrow(subsample_ILEC)){
* this_sample &lt;- subsample_ILEC$Time[-i]
  sample_mean &lt;- c(sample_mean, mean(this_sample))
}
```


```r
sd(sample_mean)
```

```
## [1] 0.008833457
```

---
## What is Permutation Testing?

A resampling method that involves randomly shuffling the labels (e.g., conditions) across the data and recomputing the test statistic of interest, thereby deriving a null distribution of the test statistic.

--

### Illustration of Permutation Testing 1

We are interested in the difference in the rating of group A and group B  restaurants. 


```
##                    name group rating
## 1    Pappy's Smokehouse     A      7
## 2               Mai Lee     A      8
## 3 Adriana's on the Hill     A      8
## 4          Salt &amp; Smoke     B      4
## 5           Chilli Spot     B      6
## 6               BLK MKT     B      7
```

---

### Illustration of Permutation Testing 2

The observed difference is...


```
##                    name group rating
## 1    Pappy's Smokehouse     A      7
## 2               Mai Lee     A      8
## 3 Adriana's on the Hill     A      8
```


```r
perm_df %&gt;% filter(group == 'A') %&gt;% pull(rating) %&gt;% mean()
```

```
## [1] 7.666667
```


```
##           name group rating
## 1 Salt &amp; Smoke     B      4
## 2  Chilli Spot     B      6
## 3      BLK MKT     B      7
```


```r
perm_df %&gt;% filter(group == 'B') %&gt;% pull(rating) %&gt;% mean()
```

```
## [1] 5.666667
```

--


```r
perm_df %&gt;% filter(group == 'A') %&gt;% pull(rating) %&gt;% mean() - perm_df %&gt;% filter(group == 'B') %&gt;% pull(rating) %&gt;% mean()
```

```
## [1] 2
```

---

### Illustration of Permutation Testing 3

Initially, the three restaurants in group A were: 


```
##                    name group rating
## 1    Pappy's Smokehouse     A      7
## 2               Mai Lee     A      8
## 3 Adriana's on the Hill     A      8
```

--

Now, we are going to randomly assign restaurants to group A and group B, and calculate the mean difference in ratings. 


```r
random_indices &lt;- sample.int(nrow(perm_df), 3)
random_A &lt;- perm_df[random_indices,]
random_B &lt;- perm_df[-random_indices,]

random_A %&gt;% pull(name)
```

```
## [1] "Mai Lee"               "Adriana's on the Hill" "Chilli Spot"
```


```r
random_A %&gt;% pull(rating) %&gt;% mean() - random_B %&gt;% pull(rating) %&gt;% mean()
```

```
## [1] 1.333333
```

---
### Illustration of Permutation Testing 4

We will repeat the previous step numerous times and use the mean differences to impose a null distribution of mean differences. 



&lt;img src="bootstrapping_lecture_messi_files/figure-html/unnamed-chunk-52-1.png" width="504" /&gt;


--

If we had a bigger dataset and repeated the permutation 1,000 times, we could count the number of permutations that have larger test statistic value than the observed difference, which would be equivalent to the p-value (or the probability that a test statistic is greater than or equal to the observed value, **under the null**).

---

### Final Exercise

Initially, we had 23 CLEC and 1,664 ILEC customers. **First**, we are going to calculate the mean difference in waiting time between the two groups using the observed data. 


```r
subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")

(mean(subsample_CLEC$Time) - mean(subsample_ILEC$Time))
```

```
## [1] 8.09752
```

---

### Second Step

We are going to randomly shuffle the labels of groups (previous CLEC and ILEC labels don't matter!). Label 23 random customers as CLEC and 1,664 random customers as ILEC 1,000 times, and store the mean difference in waiting time between the two groups inside a list. 

--

One iteration would look something like this: 


```r
random_indices &lt;- sample.int(nrow(Verizon), 23)
random_CLEC &lt;- Verizon[random_indices,]
random_ILEC &lt;- Verizon[-random_indices,]

(mean(random_CLEC$Time) - mean(random_ILEC$Time))
```

```
## [1] 1.13697
```

---
## Exercise: Repeat 1,000 times and derive p-value

One iteration would look something like this: 


```r
random_indices &lt;- sample.int(nrow(Verizon), 23)
random_CLEC &lt;- Verizon[random_indices,]
random_ILEC &lt;- Verizon[-random_indices,]

(mean(random_CLEC$Time) - mean(random_ILEC$Time))
```

```
## [1] 5.279976
```

### Analysis Plan

1. Put this in a for loop

--

2. Construct a list of mean differences

--

3. Determine the number of (random) mean differences greater than the observed difference in means (8.10). 

---

### One Way to do this


```r
subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")
observed_diff &lt;- mean(subsample_CLEC$Time) - mean(subsample_ILEC$Time)

set.seed(1048596) # Set random seed
perm = 1000 # Set number of permutations

*differences &lt;- NULL
```

---

### One Way to do this


```r
subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")
observed_diff &lt;- mean(subsample_CLEC$Time) - mean(subsample_ILEC$Time)

set.seed(1048596) # Set random seed
perm = 1000 # Set number of permutations

differences &lt;- NULL

for (i in 1:perm){
  random_indices &lt;- sample.int(nrow(Verizon), 23)
  random_CLEC &lt;- Verizon[random_indices,]
  random_ILEC &lt;- Verizon[-random_indices,]
  
* differences &lt;- c(differences,
*                  mean(random_CLEC$Time) - mean(random_ILEC$Time))
}
```


---

### One Way to do this


```r
subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")
observed_diff &lt;- mean(subsample_CLEC$Time) - mean(subsample_ILEC$Time)

set.seed(1048596) # Set random seed
perm = 1000 # Set number of permutations

differences &lt;- NULL

for (i in 1:perm){
  random_indices &lt;- sample.int(nrow(Verizon), 23)
  random_CLEC &lt;- Verizon[random_indices,]
  random_ILEC &lt;- Verizon[-random_indices,]
  
  differences &lt;- c(differences, 
                   mean(random_CLEC$Time) - mean(random_ILEC$Time))
}

*paste("Number of mean differences greater than observed difference: ", sum(differences &gt; observed_diff))
```

```
## [1] "Number of mean differences greater than observed difference:  24"
```

```r
*paste("p-value: ", sum(differences &gt; observed_diff)/length(differences))
```

```
## [1] "p-value:  0.024"
```

---

### Visualization
&lt;img src="bootstrapping_lecture_messi_files/figure-html/unnamed-chunk-59-1.png" width="504" /&gt;

---

### Permutation Testing Summary

- Permutation testing is useful for hypothesis testing because we can easily derive a p-value

- Can be used when data violates common assumptions about the data (i.e., homogeneity of variance and normality)

--

### Some Caveats

- Assumption that the observations need to be exchangeable. Some observations may not be exchangeable (e.g., time series data - data collected at different time points)

- Sample size needs to be large. No point randomly shuffling 1,000 times when the possible permutation is less than 1000. 

---

class: inverse

## Next time ...

- Thursday: One more machine learning lecture 

- Don't forget to read Yarkoni &amp; Westfall, 2017!

- Next Tuesday: Final review session
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
