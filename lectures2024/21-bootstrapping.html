<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Resampling Methods</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.25/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Resampling Methods
]

---


&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 30px;
    padding: 1em 4em 1em 4em;
}

.small .remark-code { 
  font-size: 80% !important;
}
.tiny .remark-code {
  font-size: 50% !important;
}

&lt;/style&gt;




## Last time...

### Review Lecture

* Weighted Least Squares (WLS)
* Worked on assignment

--

## Today

* Start looking at topics related to machine learning
* We are going to start off with __Resampling methods__

---
## First. Sampling

It is impossible to survey every person in the population we are interested in, so we often take a "random sample" from the population and calculate a **sample statistic** (e.g., mean, median). 

--

A lot of our statistics follow well-defined distributions (e.g., normal distribution), and we use the properties of these distributions to estimate the population parameter. 

---
## Problems with Sampling

### Single Estimate of the Population Parameter

- Estimate the population mean

- Sampling distribution of mean derived from sample statistics

- Built a 95% confidence interval around the sample mean

- We've been **relying on a single estimate** of the population parameter. 

---

class: inverse, center, middle

### We make assumptions about the sample (e.g., representative sample, large sample size, normality), which may or may not be true.

---
### Introduction to Resampling

A statistical technique that involves re-estimation of the population parameter by repeatedly drawing samples from **the original sample**

---

### Reasons for Resampling

- Reduce bias of the estimate by using multiple samples instead of one
  
- Better sense of precision of the estimated population parameter
  
- We do not need to make assumptions about the population distribution (e.g., when we perform two samples t-test, for example, we make the assumption that the populations from which the samples are drawn are normally distributed)
  
- Sample does not have to be large

---
### Types of Resampling

- Bootstrapping

- Jackknife method (just a glimpse)

- Permutation testing (just a glimpse; Research Methods will cover it)

---

&gt; **pull yourself up by your bootstraps**

--

Improve yourself/overcome (often impossible) obstacles without aid or assistance from anyone else. Use your own resources to improve your standing.

![](images/bootstraps.png)


---
### Bootstrapping

**Bootstrapping** is a method where we *rely entirely on the sample that we have at hand*.

- We randomly sample within the sample (with replacement)

- Compute the estimator of interest in order to...

- Build an empirical distribution of that test statistic.

---
### Illustration of Bootstrapping

Imagine we are trying to estimate the height of a cohort of friends. But you only have 6. Specifically, these 6 friends.

--

![](images/friends.png)


---

To estimate their height, you decide to perform bootstrapping, meaning you draw many samples from this group of 6 people, *with replacement*, each time calculating the average height of the sample.

--


```
## [1] "Ross"     "Rachel"   "Chandler" "Monica"   "Monica"   "Rachel"
```

```
## [1] "Mean height of this sample: 168.5"
```

--

The number of friends that we randomly sample is 6, the same number of friends inside the initial sample. 

Within the same sample, there can be duplicates. This is what it means to randomly sample **with replacement**. 

---
## Repeat


```
## [1] "Rachel"   "Phoebe"   "Ross"     "Monica"   "Monica"   "Chandler"
```

```
## [1] "Mean height of this sample: 169.666666666667"
```
--

```
## [1] "Monica"   "Phoebe"   "Chandler" "Chandler" "Rachel"   "Chandler"
```

```
## [1] "Mean height of this sample: 170.166666666667"
```
--

```
## [1] "Chandler" "Rachel"   "Chandler" "Chandler" "Joey"     "Rachel"
```

```
## [1] "Mean height of this sample: 169.833333333333"
```

---
### Bootstrap 10,000 Times


```r
# When resampling, it is generally a good practice to set random seed
# for full reproducibility of the resampling process
set.seed(5067)

boot &lt;- 10000 # Set number of bootstrap samples

friends = c('Monica', 'Rachel', 'Ross', 'Joey', 'Phoebe', 'Chandler')
heights &lt;- c(165, 165, 178, 170, 172, 173)

sample_means &lt;- NULL # Initialize list to store sample means
```

---
### Bootstrap 10,000 Times


```r
# When resampling, it is generally a good practice to set random seed
# for full reproducibility of the resampling process
set.seed(5067)

boot &lt;- 10000 # Set number of bootstrap samples

friends = c('Monica', 'Rachel', 'Ross', 'Joey', 'Phoebe', 'Chandler')
heights &lt;- c(165, 165, 178, 170, 172, 173)

sample_means &lt;- NULL # Initialize list to store sample means

# Append the mean of bootstrap sample heights to *sample_means*
*for(i in 1:boot){
* this_sample &lt;- sample(heights, size = length(heights), replace = T)
* sample_means &lt;- c(sample_means, mean(this_sample))
*} 
```

---
### Comparison

&lt;img src="21-bootstrapping_files/figure-html/unnamed-chunk-7-1.png" width="720" /&gt;

---

There are several candidates for central tendency (e.g., mean, median) and for variability (e.g., standard deviation, interquartile range). **Some of these do not have well understood theoretical sampling distributions.**

For the mean and standard deviation, we have theoretical sampling distributions to help us, provided we think the mean and standard deviation are the best indices. For the others, we can use bootstrapping.

---
### Example 2

Central tendency and variability of 216 reaction times


```r
# Set random seed before generating data
set.seed(5067)

# The observations generally follow the F Distribution + random noise
response = rf(n = 216, 3, 50) 
response = response * 500 + rnorm(n = 216, mean = 200, sd = 100)
```

---
### Visualize Data
&lt;img src="21-bootstrapping_files/figure-html/unnamed-chunk-9-1.png" width="648" /&gt;

---


```r
set.seed(5067) # Set random seed
boot &lt;- 10000 # Set number of bootstrap samples

response_means &lt;- NULL # Initialize list of mean values

for(i in 1:boot){
  sample_response &lt;- sample(response, size = 216, replace = T)
  response_means &lt;- c(response_means, mean(sample_response))
}
```

What is the bootstrap mean and its 95% CI?


```r
mean(response_means)
```

```
## [1] 682.5499
```

```r
quantile(response_means, probs = c(.025, .975))
```

```
##     2.5%    97.5% 
## 633.2482 732.0461
```

---

### Distribution of Means

&lt;img src="21-bootstrapping_files/figure-html/unnamed-chunk-12-1.png" width="648" /&gt;

---


```r
set.seed(5067)
boot &lt;- 10000
response_med &lt;- NULL

for(i in 1:boot){
  sample_response &lt;- sample(response, size = 216, replace = T)
  response_med &lt;- c(response_med, median(sample_response))}
```
.pull-left[
&lt;img src="21-bootstrapping_files/figure-html/unnamed-chunk-14-1.png" width="504" /&gt;
]
.pull-right[

```r
mean(response_med)
```

```
## [1] 600.4248
```

```r
median(response_med)
```

```
## [1] 598.9464
```

```r
quantile(response_med, 
         probs = c(.025, .975))
```

```
##     2.5%    97.5% 
## 542.0469 665.4593
```
]

---


```r
set.seed(5067)
boot &lt;- 10000
response_sd &lt;- NULL

for(i in 1:boot){
  sample_response &lt;- sample(response, size = 216, replace = T)
  response_sd &lt;- c(response_sd, sd(sample_response))}
```
.pull-left[
&lt;img src="21-bootstrapping_files/figure-html/unnamed-chunk-17-1.png" width="504" /&gt;
]
.pull-right[

```r
mean(response_sd)
```

```
## [1] 374.7614
```

```r
median(response_sd)
```

```
## [1] 374.299
```

```r
quantile(response_sd, 
         probs = c(.025, .975))
```

```
##     2.5%    97.5% 
## 326.6762 425.9399
```
]

---
### Other Estimators?

You can bootstrap estimates and 95% confidence intervals for *any* statistics you'll need to estimate. 

Things you should learn how to do in `R`:
- learn to read a `for loop`
- learn to write your own function

---

The `boot` package and function provides some help to speed this process along. Things you should learn how to do in R:



```r
library(boot)

# function to obtain R-Squared from the data
rsq &lt;- function(data, indices) {
  d &lt;- data[indices,] # allows boot to select sample
  fit &lt;- lm(mpg ~ wt + disp, data = d) # this is the code you would have run
  return(summary(fit)$r.square)
}

results &lt;- boot(data = mtcars, statistic = rsq, R = 10000)
```

---
.pull-left[
&lt;img src="21-bootstrapping_files/figure-html/unnamed-chunk-20-1.png" width="504" /&gt;
]

.pull-right[

```r
median(results$t)
```

```
## [1] 0.7972849
```

```r
boot.ci(results, type = "perc")
```

```
## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 10000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = results, type = "perc")
## 
## Intervals : 
## Level     Percentile     
## 95%   ( 0.6862,  0.8771 )  
## Calculations and Intervals on Original Scale
```
]

---
### Another Example

In this district, Verizon provides line service to both Verizon and non-Verizon customers. Here, we are going to look at a dataset containing service waiting times for Verizon customers (ILEC) and non-Verizon customers (CLEC). We are interested in **whether waiting time of non-Verizon customers is longer than that of Verizon customers**. 





```r
head(Verizon, 3)
```

```
##   Time Group
## 1 17.5  ILEC
## 2  2.4  ILEC
## 3  0.0  ILEC
```

---
### Inspect Verizon Data 1

&lt;img src="21-bootstrapping_files/figure-html/unnamed-chunk-24-1.png" width="720" /&gt;

- Left is the distribution of waiting times of Non-Verizon (CLEC) customers; and
- Right is the distribution of waiting times of Verizon (ILEC) customers. 

--

Both distributions are not normal.

---
### Inspect Verizon Data 2

&lt;img src="21-bootstrapping_files/figure-html/unnamed-chunk-25-1.png" width="720" /&gt;

```
## 
## CLEC ILEC 
##   23 1664
```

--

The groups are (very) unbalanced. 

---
### Analysis Plan and Justification 

It seems that the data do not meet the typical assumptions of an independent samples `\(t\)`-test.

In this case, to estimate mean differences we can use bootstrapping.

Here, we'll resample with replacement separately from the two samples and calculate their difference in means.

---

```r
# Set random seed and number of bootstrap samples
set.seed(5067)
boot &lt;- 10000

response_means &lt;- NULL

for(i in 1:boot){
  sample_response &lt;- sample(response, size = 216, replace = T)
  response_means &lt;- c(response_means,mean(sample_response))
}
```


**Inside the For Loop**

- Sample (with replacement) Verizon group (ILEC) customers
- Sample (with replacement) non-Verizon group (CLEC) customers
- Calculate the difference in means between the two groups
- Append the difference value to a list


---
### One Solution


```r
set.seed(5067)
boot &lt;- 10000
difference &lt;- NULL

*subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
*subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")
```

---
### One Solution


```r
set.seed(5067)
boot &lt;- 10000
difference &lt;- NULL

subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")

for(i in 1:boot){
  # Sample (with replacement) Verizon group (ILEC) customers
* sample_CLEC = sample(subsample_CLEC$Time,
*                      size = nrow(subsample_CLEC),
*                      replace = T)
  # Sample (with replacement) Non-Verizon group (CLEC) customers
* sample_ILEC = sample(subsample_ILEC$Time,
*                      size = nrow(subsample_ILEC),
*                      replace = T)
}
```

---
### One Solution


```r
set.seed(5067)
boot &lt;- 10000
difference &lt;- NULL

subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")

for(i in 1:boot){
  # Sample (with replacement) Verizon group (ILEC) customers
  sample_CLEC = sample(subsample_CLEC$Time, 
                       size = nrow(subsample_CLEC), 
                       replace = T)
  # Sample (with replacement) Non-Verizon group (CLEC) customers
  sample_ILEC = sample(subsample_ILEC$Time, 
                       size = nrow(subsample_ILEC), 
                       replace = T)
  
  # Calculate the difference in means between the two groups
  # Append the difference value to a list
* difference &lt;- c(difference, mean(sample_CLEC) - mean(sample_ILEC))
}
```

---
### Bootstrap Distribution of Differences

&lt;img src="21-bootstrapping_files/figure-html/unnamed-chunk-30-1.png" width="720" /&gt;

The difference in means is 7.64 `\([1.66,16.98]\)`. What would this mean?

--

Bootstrap CI does not include 0. There is a difference in the waiting time of Verizon and non-Verizon customers in the expected direction

---

Bootstrapping is useful when:

--

1. Violated assumptions of the test (e.g., normality)

--

2. You have good reason to believe the sampling distribution is not normal, but don't know what it is (e.g., median)

--

3. Oddities in your data, like very unbalanced samples 

--

This allows you to create a confidence interval around any statistic you want. You can test whether these statistics are significantly different from any other value. 

---

Bootstrapping will **NOT** help you deal with:

--

* Dependence between observations -- for this, you'll need to explicitly model dependence

--

* Improperly specified models or forms -- use theory to guide you here

--

* Measurement error -- why bother?

--

* Caveats: representativeness of the sample, outliers

---
## Jackknife Resampling

**Jackknife Resampling** is a method where researchers generate n sub-samples, each leaving out one observation. The method is very similar to bootstrapping except **the way that we create the sub-samples**.

---
Friends Example. If you decide to jackknife their heights, you would draw six sub-samples and calculate their respective mean height.


```r
friends = c('Monica', 'Rachel', 'Ross', 'Joey', 'Phoebe', 'Chandler')
heights = c(165, 165, 178, 170, 172, 173)
names(heights) = friends
```
--

```
## [1] "First Sub-sample:  Rachel, Ross, Joey, Phoebe, Chandler"
```
--

```
## [1] "Second Sub-sample:  Monica, Ross, Joey, Phoebe, Chandler"
```
--

```
## [1] "Third Sub-sample:  Monica, Rachel, Joey, Phoebe, Chandler"
```
--

```
## [1] "Fourth Sub-sample:  Monica, Rachel, Ross, Phoebe, Chandler"
```
--

```
## [1] "Fifth Sub-sample:  Monica, Rachel, Ross, Joey, Chandler"
```
--

```
## [1] "Sixth Sub-sample:  Monica, Rachel, Ross, Joey, Phoebe"
```

Notice that there are **6** sub-samples of **size 5**. 

---
### Jack of all trades, master of none - Jackknife
1. Can assess the accuracy of a statistical estimator without making assumptions about the underlying distribution

2. Computationally efficient bc only *n* sub-samples are generated (compared to 10,000 for example)

3. Not used as much these days

4. Sensitive to sample size: If sample size is small, it can result in inaccurate estimates of the bias (e.g., sample size of 6 means six jackknife samples).


---
### Permutation Testing

A resampling method that involves **randomly shuffling the labels** (e.g., conditions) across the data and recomputing the test statistic of interest, thereby deriving a null distribution of the test statistic.

---

### Permutation Example: Restaurants

We are interested in the difference in the rating of group A and group B  restaurants. 


```
##                    name group rating
## 1    Pappy's Smokehouse     A      7
## 2               Mai Lee     A      8
## 3 Adriana's on the Hill     A      8
## 4          Salt &amp; Smoke     B      4
## 5           Chilli Spot     B      6
## 6               BLK MKT     B      7
```

---
### Permutation Example: Restaurants

The observed difference is...


```
##                    name group rating
## 1    Pappy's Smokehouse     A      7
## 2               Mai Lee     A      8
## 3 Adriana's on the Hill     A      8
```


```
## [1] 7.666667
```


```
##           name group rating
## 1 Salt &amp; Smoke     B      4
## 2  Chilli Spot     B      6
## 3      BLK MKT     B      7
```


```
## [1] 5.666667
```

--


```r
perm_df %&gt;% filter(group == 'A') %&gt;% pull(rating) %&gt;% mean() - perm_df %&gt;% filter(group == 'B') %&gt;% pull(rating) %&gt;% mean()
```

```
## [1] 2
```

---

Initially, the three restaurants in group A were: 


```
##                    name group rating
## 1    Pappy's Smokehouse     A      7
## 2               Mai Lee     A      8
## 3 Adriana's on the Hill     A      8
```

---

Now, we are going to randomly assign restaurants to group A and group B, and calculate the mean difference in ratings. 


```r
random_indices &lt;- sample.int(nrow(perm_df), 3)
random_A &lt;- perm_df[random_indices,]
random_B &lt;- perm_df[-random_indices,]

random_A %&gt;% pull(name)
```

```
## [1] "Salt &amp; Smoke" "Mai Lee"      "Chilli Spot"
```


```r
random_A %&gt;% pull(rating) %&gt;% mean() - random_B %&gt;% pull(rating) %&gt;% mean()
```

```
## [1] -1.333333
```

---

.small[Repeat the previous step numerous times to impose a null distribution of mean differences]



&lt;img src="21-bootstrapping_files/figure-html/unnamed-chunk-48-1.png" width="504" /&gt;


We could count the number of permutations that have larger test statistic value than the observed difference, which would be equivalent to the `\(p\)`-value (or the probability that a test statistic is greater than or equal to the observed value, **under the null**).

---

### Let's Try

Initially, we had 23 CLEC and 1,664 ILEC customers. **First**, we are going to calculate the mean difference in waiting time between the two groups using the observed data. 


```r
subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")

(mean(subsample_CLEC$Time) - mean(subsample_ILEC$Time))
```

```
## [1] 8.09752
```

---

### Second Step

We are going to randomly shuffle the labels of groups (previous CLEC and ILEC labels don't matter!). Label 23 random customers as CLEC and 1,664 random customers as ILEC 1,000 times, and store the mean difference in waiting time between the two groups inside a list. 

--

One iteration would look something like this: 


```r
random_indices &lt;- sample.int(nrow(Verizon), 23)
random_CLEC &lt;- Verizon[random_indices,]
random_ILEC &lt;- Verizon[-random_indices,]

(mean(random_CLEC$Time) - mean(random_ILEC$Time))
```

```
## [1] 2.394109
```

---
### Repeat 1,000 times to derive the *p*-value

One iteration would look something like this: 


```r
random_indices &lt;- sample.int(nrow(Verizon), 23)
random_CLEC &lt;- Verizon[random_indices,]
random_ILEC &lt;- Verizon[-random_indices,]

(mean(random_CLEC$Time) - mean(random_ILEC$Time))
```

```
## [1] -0.3775922
```

---
### Analysis Plan

1. Put this in a for loop

--

2. Construct a list of mean differences

--

3. Determine the number of (random) mean differences greater than the observed difference in means (8.10). 

---

### One Way to do this


```r
subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")
observed_diff &lt;- mean(subsample_CLEC$Time) - mean(subsample_ILEC$Time)

set.seed(1048596) # Set random seed
perm = 1000 # Set number of permutations

*differences &lt;- NULL
```

---

### One Way to do this


```r
subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")
observed_diff &lt;- mean(subsample_CLEC$Time) - mean(subsample_ILEC$Time)

set.seed(1048596) # Set random seed
perm = 1000 # Set number of permutations

differences &lt;- NULL

for (i in 1:perm){
  random_indices &lt;- sample.int(nrow(Verizon), 23)
  random_CLEC &lt;- Verizon[random_indices,]
  random_ILEC &lt;- Verizon[-random_indices,]
  
* differences &lt;- c(differences,
*                  mean(random_CLEC$Time) - mean(random_ILEC$Time))
}
```


---



```r
subsample_CLEC = Verizon %&gt;% filter(Group == "CLEC")
subsample_ILEC = Verizon %&gt;% filter(Group == "ILEC")
observed_diff &lt;- mean(subsample_CLEC$Time) - mean(subsample_ILEC$Time)

set.seed(1048596) # Set random seed
perm = 1000 # Set number of permutations

differences &lt;- NULL

for (i in 1:perm){
  random_indices &lt;- sample.int(nrow(Verizon), 23)
  random_CLEC &lt;- Verizon[random_indices,]
  random_ILEC &lt;- Verizon[-random_indices,]
  
  differences &lt;- c(differences, 
                   mean(random_CLEC$Time) - mean(random_ILEC$Time))
}

*paste("Number of mean differences greater than observed difference: ", sum(differences &gt; observed_diff))
```

```
## [1] "Number of mean differences greater than observed difference:  24"
```

```r
*paste("p-value: ", sum(differences &gt; observed_diff)/length(differences))
```

```
## [1] "p-value:  0.024"
```

---

### Visualization
&lt;img src="21-bootstrapping_files/figure-html/unnamed-chunk-55-1.png" width="504" /&gt;

---

### Permutation Testing Summary

- Permutation testing is useful for hypothesis testing because we can easily derive a `\(p\)`-value
- Can be used when data violates common assumptions about the data (i.e., homogeneity of variance and normality)
- Assumption that the observations need to be exchangeable. Some observations may not be exchangeable (e.g., time series data - data collected at different time points)
- Sample size needs to be large. No point randomly shuffling 1,000 times when the possible permutation is less than 1000. 

---

class: inverse

## Next time ...

- Thursday: One more machine learning lecture 

- Don't forget to read Yarkoni &amp; Westfall, 2017!

- Next Tuesday: Final review session
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
