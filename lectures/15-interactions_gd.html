<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Interactions (III)</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.25/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies-fonts.css" rel="stylesheet" />
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Interactions (III)
]

---


## Last time

Mixing categorical and continuous variables

## This time

Factorial ANOVA (two categorical predictors)


---
class:inverse
## Factorial ANOVA


The interaction of two or more categorical variables in a general linear model is formally known as **Factorial ANOVA**.

A factorial design is used when there is an interest in how two or more variables (a.k.a. factors) affect the outcome. 

* Rather than conduct separate one-way ANOVAs for each factor, they are all included in one analysis. 

* The unique and important advantage to a factorial ANOVA over separate one-way ANOVAs is the ability to examine interactions.


---

## Two categorical predictors

If both X and M are categorical variables, the interpretation of coefficients is no longer the value of means and slopes, but means and differences in means. 

Recall our Solomon's paradox example from a few weeks ago:






```r
head(solomon[,c("PERSPECTIVE", "DISTANCE", "WISDOM")])
```

```
##   PERSPECTIVE  DISTANCE      WISDOM
## 1       other  immersed -0.27589395
## 2       other distanced  0.42949213
## 3       other distanced -0.02785874
## 4       other distanced  0.53271500
## 5        self distanced  0.62299793
## 6        self distanced -1.99578129
```

```r
solomon$PERSPECTIVE = factor(solomon$PERSPECTIVE)
solomon$DISTANCE = factor(solomon$DISTANCE)
```

---

### Model Means


```r
solomon %&gt;% 
  group_by(DISTANCE, PERSPECTIVE) %&gt;% 
  summarize(meanWISDOM = mean(WISDOM, na.rm = TRUE))
```

```
## # A tibble: 4 Ã— 3
## # Groups:   DISTANCE [2]
##   DISTANCE  PERSPECTIVE meanWISDOM
##   &lt;fct&gt;     &lt;fct&gt;            &lt;dbl&gt;
## 1 distanced other            0.334
## 2 distanced self             0.122
## 3 immersed  other            0.195
## 4 immersed  self            -0.559
```

---


```r
summary(lm(WISDOM ~ PERSPECTIVE*DISTANCE, data = solomon))
```

```
## 
## Call:
## lm(formula = WISDOM ~ PERSPECTIVE * DISTANCE, data = solomon)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.6809 -0.4209  0.0473  0.6694  2.3499 
## 
## Coefficients:
##                                  Estimate Std. Error t value Pr(&gt;|t|)  
*## (Intercept)                        0.3345     0.1878   1.781   0.0776 .
## PERSPECTIVEself                   -0.2124     0.2630  -0.808   0.4210  
## DISTANCEimmersed                  -0.1396     0.2490  -0.561   0.5760  
## PERSPECTIVEself:DISTANCEimmersed  -0.5417     0.3526  -1.536   0.1273  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9389 on 111 degrees of freedom
##   (5 observations deleted due to missingness)
## Multiple R-squared:  0.1262,	Adjusted R-squared:  0.1026 
## F-statistic: 5.343 on 3 and 111 DF,  p-value: 0.001783
```

---



```r
summary(lm(WISDOM ~ PERSPECTIVE*DISTANCE, data = solomon))
```

```
## 
## Call:
## lm(formula = WISDOM ~ PERSPECTIVE * DISTANCE, data = solomon)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.6809 -0.4209  0.0473  0.6694  2.3499 
## 
## Coefficients:
##                                  Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)                        0.3345     0.1878   1.781   0.0776 .
*## PERSPECTIVEself                   -0.2124     0.2630  -0.808   0.4210  
## DISTANCEimmersed                  -0.1396     0.2490  -0.561   0.5760  
## PERSPECTIVEself:DISTANCEimmersed  -0.5417     0.3526  -1.536   0.1273  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9389 on 111 degrees of freedom
##   (5 observations deleted due to missingness)
## Multiple R-squared:  0.1262,	Adjusted R-squared:  0.1026 
## F-statistic: 5.343 on 3 and 111 DF,  p-value: 0.001783
```

---


```r
summary(lm(WISDOM ~ PERSPECTIVE*DISTANCE, data = solomon))
```

```
## 
## Call:
## lm(formula = WISDOM ~ PERSPECTIVE * DISTANCE, data = solomon)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.6809 -0.4209  0.0473  0.6694  2.3499 
## 
## Coefficients:
##                                  Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)                        0.3345     0.1878   1.781   0.0776 .
## PERSPECTIVEself                   -0.2124     0.2630  -0.808   0.4210  
*## DISTANCEimmersed                  -0.1396     0.2490  -0.561   0.5760  
## PERSPECTIVEself:DISTANCEimmersed  -0.5417     0.3526  -1.536   0.1273  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9389 on 111 degrees of freedom
##   (5 observations deleted due to missingness)
## Multiple R-squared:  0.1262,	Adjusted R-squared:  0.1026 
## F-statistic: 5.343 on 3 and 111 DF,  p-value: 0.001783
```

---

```r
summary(lm(WISDOM ~ PERSPECTIVE*DISTANCE, data = solomon))
```

```
## 
## Call:
## lm(formula = WISDOM ~ PERSPECTIVE * DISTANCE, data = solomon)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.6809 -0.4209  0.0473  0.6694  2.3499 
## 
## Coefficients:
##                                  Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)                        0.3345     0.1878   1.781   0.0776 .
## PERSPECTIVEself                   -0.2124     0.2630  -0.808   0.4210  
## DISTANCEimmersed                  -0.1396     0.2490  -0.561   0.5760  
*## PERSPECTIVEself:DISTANCEimmersed  -0.5417     0.3526  -1.536   0.1273  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9389 on 111 degrees of freedom
##   (5 observations deleted due to missingness)
## Multiple R-squared:  0.1262,	Adjusted R-squared:  0.1026 
## F-statistic: 5.343 on 3 and 111 DF,  p-value: 0.001783
```

---



```r
summary(lm(WISDOM ~ PERSPECTIVE*DISTANCE, data = solomon))
```

```
## 
## Call:
## lm(formula = WISDOM ~ PERSPECTIVE * DISTANCE, data = solomon)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.6809 -0.4209  0.0473  0.6694  2.3499 
## 
## Coefficients:
##                                  Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)                        0.3345     0.1878   1.781   0.0776 .
## PERSPECTIVEself                   -0.2124     0.2630  -0.808   0.4210  
## DISTANCEimmersed                  -0.1396     0.2490  -0.561   0.5760  
## PERSPECTIVEself:DISTANCEimmersed  -0.5417     0.3526  -1.536   0.1273  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9389 on 111 degrees of freedom
##   (5 observations deleted due to missingness)
*## Multiple R-squared:  0.1262,	Adjusted R-squared:  0.1026 
## F-statistic: 5.343 on 3 and 111 DF,  p-value: 0.001783
```

---



```r
summary(lm(WISDOM ~ PERSPECTIVE*DISTANCE, data = solomon))
```

```
## 
## Call:
## lm(formula = WISDOM ~ PERSPECTIVE * DISTANCE, data = solomon)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.6809 -0.4209  0.0473  0.6694  2.3499 
## 
## Coefficients:
##                                  Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)                        0.3345     0.1878   1.781   0.0776 .
## PERSPECTIVEself                   -0.2124     0.2630  -0.808   0.4210  
## DISTANCEimmersed                  -0.1396     0.2490  -0.561   0.5760  
## PERSPECTIVEself:DISTANCEimmersed  -0.5417     0.3526  -1.536   0.1273  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9389 on 111 degrees of freedom
##   (5 observations deleted due to missingness)
## Multiple R-squared:  0.1262,	Adjusted R-squared:  0.1026 
*## F-statistic: 5.343 on 3 and 111 DF,  p-value: 0.001783
```

### Practice on your own: 

Can you recreate the cell means from the previous page using this output? 
---

### What looks different? 


```r
anova(lm(WISDOM ~ PERSPECTIVE*DISTANCE, data = solomon))
```

```
## Analysis of Variance Table
## 
## Response: WISDOM
##                       Df Sum Sq Mean Sq F value   Pr(&gt;F)   
## PERSPECTIVE            1  7.289  7.2888  8.2679 0.004838 **
## DISTANCE               1  4.761  4.7615  5.4011 0.021944 * 
## PERSPECTIVE:DISTANCE   1  2.081  2.0811  2.3607 0.127273   
## Residuals            111 97.855  0.8816                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```


---

### Plotting results


```r
solomon.mod = lm(WISDOM ~ PERSPECTIVE*DISTANCE, data = solomon)
plot_model(solomon.mod, type = "int")
```

![](15-interactions_gd_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;

---



.pull-left[
These next example data are from a simulated study in which 180 participants performed an eye-hand coordination task in which they were required to keep a mouse pointer on a red dot that moved in a circular motion.  
]
.pull-right[
![](images/dot.jpg)
]

The outcome was the time of the 10th failure (higher time, better at task). The experiment used a completely crossed, 3 x 3 factorial design. One factor was dot speed: .5, 1, or 1.5 revolutions per second (Slow, Medium, or Fast).  The second factor was noise condition: no noise, controllable noise, or uncontrollable noise.

---

### Terminology: A Refresh

In a **completely crossed** factorial design, each level of one factor occurs in combination with each level of the other factor.

If equal numbers of participants occur in each combination, the design is **balanced**.  This has some distinct advantages (described later). 

| | Slow | Medium | Fast |
|:-|:-:|:-:|:-:|
| No Noise | X | X | X |
| Controllable Noise | X | X | X |
| Uncontrollable Noise | X | X | X |

---

### Terminology: A Refresh

We describe the factorial ANOVA design by the number of **levels** of each **factor.** 

  - Factor: a variable that is being manipulated or in which there are two or more groups
  
  - Level: the different groups within a factor

In this case, we have a 3 x 3 ANOVA ("three by three"), because our first factor (speed) has three levels (slow, medium, and fast) and our second factor (noise) also has three levels (none, controllable, and uncontrollable).

---

### Questions 
&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Noise &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Slow &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Medium &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Fast &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Marginal &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr grouplength="3"&gt;&lt;td colspan="5" style="border-bottom: 1px solid;"&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; None &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 630.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 525.29 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 329.28 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 495.10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Controllable &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 576.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 492.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 287.23 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 452.21 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Uncontrollable &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 594.44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 304.62 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 268.16 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 389.08 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Marginal &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 600.61 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 440.88 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 294.89 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 445.46 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


There are three important ways we can view the results of this experiment.  Two of them correspond to questions that would arise in a simple one-way ANOVA:


---

### Questions 
&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Noise &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Slow &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Medium &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Fast &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Marginal &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr grouplength="3"&gt;&lt;td colspan="5" style="border-bottom: 1px solid;"&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; None &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 630.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 525.29 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 329.28 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 495.10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Controllable &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 576.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 492.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 287.23 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 452.21 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Uncontrollable &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 594.44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 304.62 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 268.16 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 389.08 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Marginal &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 600.61 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 440.88 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 294.89 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 445.46 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


There are three important ways we can view the results of this experiment.  Two of them correspond to questions that would arise in a simple one-way ANOVA:

Regardless of noise condition, does speed of the moving dot affect performance?



---

### Questions 
&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Noise &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Slow &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Medium &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Fast &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Marginal &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr grouplength="3"&gt;&lt;td colspan="5" style="border-bottom: 1px solid;"&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; None &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 630.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 525.29 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 329.28 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 495.10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Controllable &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 576.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 492.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 287.23 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 452.21 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Uncontrollable &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 594.44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 304.62 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 268.16 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 389.08 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Marginal &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 600.61 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 440.88 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 294.89 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 445.46 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


There are three important ways we can view the results of this experiment.  Two of them correspond to questions that would arise in a simple one-way ANOVA:

Regardless of noise condition, does speed of the moving dot affect performance?

Regardless of dot speed, does noise condition affect performance?

---


&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Noise &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Slow &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Medium &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Fast &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Marginal &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr grouplength="3"&gt;&lt;td colspan="5" style="border-bottom: 1px solid;"&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; None &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 630.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 525.29 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 329.28 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 495.10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Controllable &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 576.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 492.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 287.23 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 452.21 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Uncontrollable &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 594.44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 304.62 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 268.16 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 389.08 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;color: white !important;background-color: rgba(86, 36, 87, 255) !important;"&gt; Marginal &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: white !important;background-color: rgba(86, 36, 87, 255) !important;"&gt; 600.61 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: white !important;background-color: rgba(86, 36, 87, 255) !important;"&gt; 440.88 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: white !important;background-color: rgba(86, 36, 87, 255) !important;"&gt; 294.89 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: white !important;background-color: rgba(86, 36, 87, 255) !important;"&gt; 445.46 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

We can answer those questions by examining the marginal means, which isolate one factor while collapsing across the other factor.

Regardless of noise condition, does speed of the moving dot affect performance?  
- Faster moving dots are harder to track and lead to faster average failure times.

Adding information about variability allows us a sense of whether these are significant and meaningful differences...

---


```r
library(ggpubr)
ggbarplot(data = Data, x = "Speed", y = "Time", add = c("mean_ci"), fill = "#562457", xlab = "Speed Condition", ylab = "Mean Seconds (95% CI)", title = "Failure time as a function of\nspeed condition") + cowplot::theme_cowplot(font_size = 20)
```

![](15-interactions_gd_files/figure-html/unnamed-chunk-19-1.png)&lt;!-- --&gt;

Looks like the mean differences are substantial.  The ANOVA will be able to tell us if the means are significantly different  and the magnitude of those differences in terms of variance accounted for.

---

### Marginal means

&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Noise &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Slow &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Medium &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Fast &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Marginal &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr grouplength="3"&gt;&lt;td colspan="5" style="border-bottom: 1px solid;"&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; None &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 630.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 525.29 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 329.28 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: white !important;background-color: rgba(86, 36, 87, 255) !important;"&gt; 495.10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Controllable &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 576.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 492.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 287.23 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: white !important;background-color: rgba(86, 36, 87, 255) !important;"&gt; 452.21 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Uncontrollable &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 594.44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 304.62 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 268.16 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: white !important;background-color: rgba(86, 36, 87, 255) !important;"&gt; 389.08 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Marginal &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 600.61 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 440.88 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 294.89 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: white !important;background-color: rgba(86, 36, 87, 255) !important;"&gt; 445.46 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

Regardless of dot speed, does noise condition affect performance?  
- Performance declines in the presence of noise, especially if the noise is uncontrollable.

Here, too adding information about variability allows us a sense of whether these are significant and meaningful differences...

---


```r
ggbarplot(data = Data, x = "Noise", y = "Time", add = c("mean_ci"), fill = "#562457", xlab = "Noise Condition", ylab = "Mean Seconds (95% CI)", title = "Failure time as a function of\nnoise condition") + cowplot::theme_cowplot(font_size = 20)
```

![](15-interactions_gd_files/figure-html/unnamed-chunk-21-1.png)&lt;!-- --&gt;

The mean differences are not as apparent for this factor. The ANOVA will be particularly important for informing us about statistical significance and effect size.

---

### Marginal means

&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Noise &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Slow &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Medium &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Fast &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Marginal &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr grouplength="3"&gt;&lt;td colspan="5" style="border-bottom: 1px solid;"&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; None &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 630.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 525.29 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 329.28 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 495.10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Controllable &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 576.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 492.72 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 287.23 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 452.21 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Uncontrollable &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 594.44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 304.62 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 268.16 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 389.08 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Marginal &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 600.61 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 440.88 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 294.89 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 445.46 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

The **marginal mean differences** correspond to main effects. They tell us what impact a particular factor has, ignoring the impact of the other factor. 

The remaining effect in a factorial design, and it primary advantage over separate one-way ANOVAs, is the ability to examine **conditional mean differences**. 

---




### One-way vs Factorial

.pull-left[
**Marginal Mean Differences**

Results of one-way ANOVA


```r
lm(y ~ GROUP)
```

`$$\hat{Y} = b_0 + b_1D$$`

]

.pull-left[
**Conditional Mean Differences**

Results of Factorial ANOVA


```r
lm(y ~ GROUP*other_VARIABLE)
```

`$$\hat{Y} = b_0 + b_1D + b_2O + b_3DO$$`

]

---
### The Linear Model Way


```r
summary(lm(Time ~ Noise*Speed, data = Data))
```

```
## 
## Call:
## lm(formula = Time ~ Noise * Speed, data = Data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -316.23  -70.82    4.99   79.87  244.40 
## 
## Coefficients:
##                                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                       630.72      25.32  24.908  &lt; 2e-16 ***
## NoiseControllable                 -54.05      35.81  -1.509  0.13305    
## NoiseUncontrollable               -36.28      35.81  -1.013  0.31243    
## SpeedMedium                      -105.44      35.81  -2.944  0.00369 ** 
## SpeedFast                        -301.45      35.81  -8.418 1.49e-14 ***
## NoiseControllable:SpeedMedium      21.48      50.64   0.424  0.67201    
## NoiseUncontrollable:SpeedMedium  -184.39      50.64  -3.641  0.00036 ***
## NoiseControllable:SpeedFast        12.01      50.64   0.237  0.81287    
## NoiseUncontrollable:SpeedFast     -24.84      50.64  -0.490  0.62448    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 113.2 on 171 degrees of freedom
## Multiple R-squared:  0.6109,	Adjusted R-squared:  0.5927 
## F-statistic: 33.56 on 8 and 171 DF,  p-value: &lt; 2.2e-16
```

---


### Mean differences

&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Noise &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Slow &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Medium &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Fast &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Marginal &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr grouplength="3"&gt;&lt;td colspan="5" style="border-bottom: 1px solid;"&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; None &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(238, 202, 202, 255) !important;"&gt; 630.72 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(178, 212, 235, 255) !important;"&gt; 525.29 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(255, 255, 197, 255) !important;"&gt; 329.28 &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: grey !important;"&gt; 495.10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Controllable &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(238, 202, 202, 255) !important;"&gt; 576.67 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(178, 212, 235, 255) !important;"&gt; 492.72 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(255, 255, 197, 255) !important;"&gt; 287.23 &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: grey !important;"&gt; 452.21 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;" indentlevel="1"&gt; Uncontrollable &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(238, 202, 202, 255) !important;"&gt; 594.44 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(178, 212, 235, 255) !important;"&gt; 304.62 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(255, 255, 197, 255) !important;"&gt; 268.16 &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: grey !important;"&gt; 389.08 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;background-color: white !important;"&gt; Marginal &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(238, 202, 202, 255) !important;background-color: white !important;"&gt; 600.61 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(178, 212, 235, 255) !important;background-color: white !important;"&gt; 440.88 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(255, 255, 197, 255) !important;background-color: white !important;"&gt; 294.89 &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: grey !important;background-color: white !important;"&gt; 445.46 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

Are the marginal mean differences for noise condition a good representation of what is happening within each of the dot speed conditions?

If not, then we would need to say that the noise condition effect depends upon (is conditional on) dot speed.  We would have an interaction between noise condition and dot speed condition.

---


![](15-interactions_gd_files/figure-html/unnamed-chunk-28-1.png)&lt;!-- --&gt;


The noise condition means are most distinctly different in the medium speed condition. The noise condition means are clearly not different in the fast speed condition. 

---

### Interpretation of interactions

The presence of an interaction qualifies any main effect conclusions, leading to "yes, but" or "it depends" kinds of inferences.

.pull-left[

![](15-interactions_gd_files/figure-html/unnamed-chunk-29-1.png)&lt;!-- --&gt;

]

.pull-right[

Does noise condition affect failure time? 

"Yes, but the magnitude of the effect is strongest for the medium speed condition, weaker for the fast speed condition, and mostly absent for the slow speed condition."
]

---

### Interactions are symmetrical

&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Noise &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Slow &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Medium &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Fast &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Marginal &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr grouplength="3"&gt;&lt;td colspan="5" style="border-bottom: 1px solid;"&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;background-color: rgba(238, 202, 202, 255) !important;" indentlevel="1"&gt; None &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(238, 202, 202, 255) !important;"&gt; 630.72 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(238, 202, 202, 255) !important;"&gt; 525.29 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(238, 202, 202, 255) !important;"&gt; 329.28 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(238, 202, 202, 255) !important;background-color: white !important;"&gt; 495.10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;background-color: rgba(178, 212, 235, 255) !important;" indentlevel="1"&gt; Controllable &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(178, 212, 235, 255) !important;"&gt; 576.67 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(178, 212, 235, 255) !important;"&gt; 492.72 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(178, 212, 235, 255) !important;"&gt; 287.23 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(178, 212, 235, 255) !important;background-color: white !important;"&gt; 452.21 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;padding-left: 2em;background-color: rgba(255, 255, 197, 255) !important;" indentlevel="1"&gt; Uncontrollable &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(255, 255, 197, 255) !important;"&gt; 594.44 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(255, 255, 197, 255) !important;"&gt; 304.62 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(255, 255, 197, 255) !important;"&gt; 268.16 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: rgba(255, 255, 197, 255) !important;background-color: white !important;"&gt; 389.08 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: white !important;background-color: grey !important;"&gt; Marginal &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: grey !important;"&gt; 600.61 &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: grey !important;"&gt; 440.88 &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: grey !important;"&gt; 294.89 &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: grey !important;background-color: white !important;"&gt; 445.46 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

Are the marginal mean differences for speed condition a good representation of what is happening within each of the noise conditions?

If not, then we would need to say that the speed condition effect depends upon (is conditional on) noise condition.  


---

.left-column[
.small[
The speed condition means are clearly different in each noise condition, but the pattern of those differences is not the same. 

The marginal speed condition means do not represent well the means in each noise condition.

An interaction.]

]

![](15-interactions_gd_files/figure-html/unnamed-chunk-31-1.png)&lt;!-- --&gt;
---

### Null Hypotheses

| | Slow | Medium | Fast | Marginal |
|:-|:-:|:-:|:-:|:-:|
| No Noise |             `\(\mu_{11}\)` | `\(\mu_{12}\)` | `\(\mu_{13}\)` | `\(\mu_{1.}\)` |
| Controllable Noise |   `\(\mu_{21}\)` | `\(\mu_{22}\)` | `\(\mu_{23}\)` | `\(\mu_{2.}\)` |
| Uncontrollable Noise | `\(\mu_{31}\)` | `\(\mu_{32}\)` | `\(\mu_{33}\)` | `\(\mu_{3.}\)` |
| Marginal | `\(\mu_{.1}\)` | `\(\mu_{.2}\)` | `\(\mu_{.3}\)` | `\(\mu_{..}\)` `\((\mu_g)\)` |

The two main effects and the interaction represent three independent questions we can ask about the data. We have three null hypotheses to test.

One null hypothesis refers to the marginal row means.

$$
`\begin{aligned}
H_0&amp;: \mu_{1.} = \mu_{2.} = \dots = \mu_{R.}\\
H_1&amp;: \text{Not true that }\mu_{1.} = \mu_{2.} = \dots = \mu_{R.}
\end{aligned}`
$$

---

### Null Hypotheses

| | Slow | Medium | Fast | Marginal |
|:-|:-:|:-:|:-:|:-:|
| No Noise |             `\(\mu_{11}\)` | `\(\mu_{12}\)` | `\(\mu_{13}\)` | `\(\mu_{1.}\)` |
| Controllable Noise |   `\(\mu_{21}\)` | `\(\mu_{22}\)` | `\(\mu_{23}\)` | `\(\mu_{2.}\)` |
| Uncontrollable Noise | `\(\mu_{31}\)` | `\(\mu_{32}\)` | `\(\mu_{33}\)` | `\(\mu_{3.}\)` |
| Marginal | `\(\mu_{.1}\)` | `\(\mu_{.2}\)` | `\(\mu_{.3}\)` | `\(\mu_{..}\)` `\((\mu_g)\)` |

We can state this differently (it will make stating the interaction null hypothesis easier when we get to it).

$$
`\begin{aligned}
\alpha_r&amp;= \mu_{r.} - \mu_{g} \\
H_0&amp;: \alpha_1 = \alpha_2 = \dots = \alpha_R = 0\\
H_1&amp;: \text{At least one }\alpha_r \neq 0
\end{aligned}`
$$

---

### Null Hypotheses


| | Slow | Medium | Fast | Marginal |
|:-|:-:|:-:|:-:|:-:|
| No Noise |             `\(\mu_{11}\)` | `\(\mu_{12}\)` | `\(\mu_{13}\)` | `\(\mu_{1.}\)` |
| Controllable Noise |   `\(\mu_{21}\)` | `\(\mu_{22}\)` | `\(\mu_{23}\)` | `\(\mu_{2.}\)` |
| Uncontrollable Noise | `\(\mu_{31}\)` | `\(\mu_{32}\)` | `\(\mu_{33}\)` | `\(\mu_{3.}\)` |
| Marginal | `\(\mu_{.1}\)` | `\(\mu_{.2}\)` | `\(\mu_{.3}\)` | `\(\mu_{..}\)` `\((\mu_g)\)` |

The main effect for dot speed (column marginal means) can be stated similarly:


$$
`\begin{aligned}
\beta_c&amp;= \mu_{.c} - \mu_{g} \\
H_0&amp;: \beta_1 = \beta_2 = \dots = \beta_C = 0\\
H_1&amp;: \text{At least one }\beta_c \neq 0
\end{aligned}`
$$
---
### Null Hypothesis


| | Slow | Medium | Fast | Marginal |
|:-|:-:|:-:|:-:|:-:|
| No Noise |             `\(\mu_{11}\)` | `\(\mu_{12}\)` | `\(\mu_{13}\)` | `\(\mu_{1.}\)` |
| Controllable Noise |   `\(\mu_{21}\)` | `\(\mu_{22}\)` | `\(\mu_{23}\)` | `\(\mu_{2.}\)` |
| Uncontrollable Noise | `\(\mu_{31}\)` | `\(\mu_{32}\)` | `\(\mu_{33}\)` | `\(\mu_{3.}\)` |
| Marginal | `\(\mu_{.1}\)` | `\(\mu_{.2}\)` | `\(\mu_{.3}\)` | `\(\mu_{..}\)` `\((\mu_g)\)` |

The interaction is the difference between each cell mean ( `\(\mu_{rc}\)`) and the grand mean ( `\(\mu_g\)` or `\(\mu_{..}\)`) that remains *after* you remove the effects of A and B.

`$$(\alpha\beta)_{rc} = (\mu_{rc} - \mu_g) - (\mu_r - \mu_g) - (\mu_c - \mu_g)$$`

This simplifies down to:

`$$(\alpha\beta)_{rc} = \mu_{rc} - \mu_r - \mu_c + \mu_g$$`

---

### Null Hypothesis


| | Slow | Medium | Fast | Marginal |
|:-|:-:|:-:|:-:|:-:|
| No Noise |             `\(\mu_{11}\)` | `\(\mu_{12}\)` | `\(\mu_{13}\)` | `\(\mu_{1.}\)` |
| Controllable Noise |   `\(\mu_{21}\)` | `\(\mu_{22}\)` | `\(\mu_{23}\)` | `\(\mu_{2.}\)` |
| Uncontrollable Noise | `\(\mu_{31}\)` | `\(\mu_{32}\)` | `\(\mu_{33}\)` | `\(\mu_{3.}\)` |
| Marginal | `\(\mu_{.1}\)` | `\(\mu_{.2}\)` | `\(\mu_{.3}\)` | `\(\mu_{..}\)` `\((\mu_g)\)` |

The interaction null hypothesis can then be stated as follows:

$$
`\begin{aligned}
(\alpha\beta)_{rc}&amp;= \mu_{rc} - \alpha_r - \beta_c  + \mu_{..} \\
H_0&amp;: (\alpha\beta)_{11} = (\alpha\beta)_{12} = \dots = (\alpha\beta)_{RC} = 0\\
H_1&amp;: \text{At least one }(\alpha\beta)_{rc} \neq 0
\end{aligned}`
$$
---

### Putting it all together

`\(\alpha_r\)` = row marginal means - grand mean; main effect of variable A (noise)

`\(\beta_c\)` = column marginal means - grand mean; main effect of variable B (speed)

`\((\alpha\beta)_{rc}\)` = cell mean - `\(\alpha_r\)` - `\(\beta_c\)` + grand mean; interaction

`\(\epsilon_{irc}\)` = error component (independent, normally distributed)

---
### Putting it all together


`$$\large Y_{irc} = \mu + \alpha_r + \beta_c + (\alpha\beta)_{rc} + \epsilon_{irc}$$`

--

If you subtract the grand mean ( `\(\mu_g\)`) from both sides and substitute in the treatment population means, you get...


`$$Y_{irc} - \mu_g = (\mu_r - \mu_g) + (\mu_c - \mu_g) + (\mu_{rc} - \mu_r - \mu_c + \mu_g) + \epsilon_{irc}$$`
--

Now, above is working with population parameters. We don't have those. We have sample estimates. Let's replace with the notation for sample estimates: 

`$$(Y_{irc} - \bar{Y}_g) = (\bar{Y}_r - \bar{Y}_g) + (\bar{Y}_c - \bar{Y}_g) + (\bar{Y}_{rc} - \bar{Y}_r - \bar{Y}_c + \bar{Y}_g) + \\ (\bar{Y}_{irc} - \bar{Y}_{rc})$$`
--

In words, this translates to:

&gt; score - grand mean = main effect of A + main effect of B + interaction term + residual error

---
### Variability 


$$
`\begin{aligned}
\large SS_{\text{total}} &amp;= \sum_{r=1}^R\sum_{c=1}^C\sum_{i=1}^{N_{rc}}(Y_{rci}-\bar{Y}_{...})^2 \\
\large SS_{\text{Within}} &amp;= \sum_{r=1}^R\sum_{c=1}^C\sum_{i=1}^{N_{rc}}(Y_{rci}-\bar{Y}_{rc.})^2 \\
\large SS_R &amp;= CN\sum_{r=1}^R(\bar{Y}_{r..}-\bar{Y}_{...})^2\\
SS_C &amp;= RN\sum_{c=1}^C(\bar{Y}_{.c.}-\bar{Y}_{...})^2\\
\large SS_{RC} &amp;= \sum_{r=1}^R\sum_{c=1}^C\sum_{i=1}^{N_{rc}}(\bar{Y}_{rc.}-\bar{Y}_{r..}-\bar{Y}_{.c.}+\bar{Y}_{...})^2 \\
\end{aligned}`
$$

---

### Variability 

As was true for the simpler one-way ANOVA, we will partition the total variability in the data matrix into two basic parts. 

One part will represent variability **within groups**. This within-group variability is variability that has nothing to do with the experimental conditions (all participants within a particular group experience the same experimental conditions). 

The other part will be **between-group variability**.  This part will include variability due to experimental conditions.  We will further partition this between-group variability into parts due to the two main effects and the interaction.

---


### Variability 


If the design is balanced (equal cases in all conditions), then:

`$$\large SS_{\text{total}} = SS_R + SS_C + SS_{RxC} +SS_{\text{within}}$$`

`\(df\)`, `\(MS\)`, and `\(F\)` ratios are defined in the same way as they were for one-way ANOVA. We just have more of them.
$$
`\begin{aligned}
\large df_{Total} &amp;= N-1 \\
\large df_{Total} &amp;= abn - 1 \\
\large df_R &amp;= R-1 \\
\large df_C &amp;= C-1 \\
\large df_{RxC} &amp;= (R-1)(C-1) \\
\large df_{within} &amp;= ab(n-1) \\
&amp;= df_{total} - df_{R} - df_C - df_{RxC}
\end{aligned}`
$$

---

### Variability 

If the design is balanced (equal cases in all conditions), then:

`$$\large SS_{\text{total}} = SS_R + SS_C + SS_{RxC} +SS_{\text{within}}$$`

`\(df\)`, `\(MS\)`, and `\(F\)` ratios are defined in the same way as they were for one-way ANOVA. We just have more of them.

.pull-left[
$$
`\begin{aligned}
\large MS_R &amp;= \frac{SS_R}{df_R} \\
\large MS_C &amp;= \frac{SS_C}{df_C} \\
\large MS_{RxC} &amp;= \frac{SS_{RxC}}{df_{RxC}} \\
\large MS_{within} &amp;= \frac{SS_{within}}{df_{within}} \\
\end{aligned}`
$$
]

.pull-right[

Each mean square is a variance estimate.  `\(MS_{within}\)`  is the pooled estimate of the within-groups variance.  It represents only random or residual variation.  `\(MS_R\)`, `\(MS_C\)`, and `\(MS_{RxC}\)` also contain random variation, but include systematic variability too.

]

---

### F-statistics 


If the design is balanced (equal cases in all conditions), then:

`$$\large SS_{\text{total}} = SS_R + SS_C + SS_{RxC} +SS_{\text{within}}$$`

`\(df\)`, `\(MS\)`, and `\(F\)` ratios are defined in the same way as they were for one-way ANOVA. We just have more of them.

.pull-left[
$$
`\begin{aligned}
\large F_R &amp;= \frac{MS_R}{MS_{within}} \\
\\
\large F_C &amp;= \frac{MS_C}{MS_{within}} \\
\\
\large F_{RxC} &amp;= \frac{MS_{RxC}}{MS_{within}} \\
\end{aligned}`
$$

]

.pull-right[
If the null hypotheses are true, these ratios will be ~1.00 because the numerator and denominator of each estimate the same thing. Departures from 1.00 indicate that systematic variability is present. If large enough, we reject the null hypothesis (each considered separately).
]

---

### Degrees of freedom

The degrees of freedom for the different F ratios might not be the same. Different degrees of freedom define different theoretical F density distributions for determining what is an unusual value under the null hypothesis.


Which is to say, you might get the same F-ratio for two different tests, but they could have different p-values, if they represent different numbers of groups. 

---

### Interpretation of significance tests


```r
fit = lm(Time ~ Speed*Noise, data = Data)
anova(fit)
```

```
## Analysis of Variance Table
## 
## Response: Time
##              Df  Sum Sq Mean Sq  F value    Pr(&gt;F)    
## Speed         2 2805871 1402936 109.3975 &lt; 2.2e-16 ***
## Noise         2  341315  170658  13.3075 4.252e-06 ***
## Speed:Noise   4  295720   73930   5.7649 0.0002241 ***
## Residuals   171 2192939   12824                       
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

Interpretation?

--
All three null hypotheses are rejected.  This only tells us that systemic differences among the means are present; follow-up comparisons are necessary to determine the nature of the differences. 
---

### Interpretation of significance tests


```r
fit = lm(Time ~ Speed*Noise, data = Data)
anova(fit)
```

```
## Analysis of Variance Table
## 
## Response: Time
##              Df  Sum Sq Mean Sq  F value    Pr(&gt;F)    
## Speed         2 2805871 1402936 109.3975 &lt; 2.2e-16 ***
## Noise         2  341315  170658  13.3075 4.252e-06 ***
## Speed:Noise   4  295720   73930   5.7649 0.0002241 ***
## Residuals   171 2192939   12824                       
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

Both main effects and the interaction are significant.

The significant interaction qualifies the main effects:

- The magnitude of the speed main effect varies across the noise conditions.

- The magnitude of the noise main effect varies across the speed conditions.

---

### Visualizing main effects and interactions

Different combinations of main effects and interactions yield different shapes when plotted. An important skill is recognizing how plots will change based on the presence or absence of specific effects. 

Main effects are tests of differences in means; a significant main effect will yield a difference -- the mean of Group 1 will be different than the mean of Group 2, for example.

Interactions are tests of the differences of differences of means -- is the difference between Group 1 and Group 2 different in Condition A than that difference is in Condition B, for example.

---

### Visualizing main effects and interactions

![](15-interactions_gd_files/figure-html/unnamed-chunk-34-1.png)&lt;!-- --&gt;

???
No effect of A
Main effect of B
No interaction
---

### Visualizing main effects and interactions

![](15-interactions_gd_files/figure-html/unnamed-chunk-35-1.png)&lt;!-- --&gt;
???
Main effect of A
Main effect of B
Interaction
---

### Visualizing main effects and interactions

![](15-interactions_gd_files/figure-html/unnamed-chunk-36-1.png)&lt;!-- --&gt;

???
No effect of A
No effect of B
Interaction
---

### Pop Quiz

How would you plot....

* A main effect of A, no main effect of B, and no interaction?
* A main effect of A, a main effect of B, and no interaction?
* No main effect of A, a main effect of B, and an interaction?

---

## Effect size

All of the effects in the ANOVA are statistically significant, but how big are they?  An effect size, `\(\eta^2\)`, provides a simple way of indexing effect magnitude for ANOVA designs, especially as they get more complex.

`$$\large \eta^2 = \frac{SS_{\text{effect}}}{SS_{\text{total}}}$$`
If the design is balanced...

`$$\large SS_{\text{total}} = SS_{\text{speed}} + SS_{\text{noise}}+SS_{\text{speed:noise}}+SS_{\text{within}}$$`
---


&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Source &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; SS &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; `\(\eta^2\)` &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; `\(\text{partial }\eta^2\)` &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Speed &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2805871.4 &lt;/td&gt;
   &lt;td style="text-align:right;width: 10em; "&gt; 0.50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.56 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Noise &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 341315.2 &lt;/td&gt;
   &lt;td style="text-align:right;width: 10em; "&gt; 0.06 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.13 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Speed:Noise &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 295719.7 &lt;/td&gt;
   &lt;td style="text-align:right;width: 10em; "&gt; 0.05 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.12 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Residuals &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2192938.9 &lt;/td&gt;
   &lt;td style="text-align:right;width: 10em; "&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Total &lt;/td&gt;
   &lt;td style="text-align:right;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;width: 10em; "&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

The Speed main effect accounts for 8 to 9 times as much variance in the outcome as the Noise main effect and the Speed x Noise interaction.

---

![](images/eta_sq.jpg)
---

### `\(\eta^2\)`

.pull-left[
**If the design is balanced:**

There is no overlap among the independent variables. They are uncorrelated.

The variance accounted for by any effect is unique. There is no ambiguity about the source of variance accounted for in the outcome.

The sum of the `\(\eta^2\)` for effects and residual is 1.00.
]

.pull-right[
![](images/eta_sq.jpg)
]

---

### `\(\eta^2\)`

One argument against `\(\eta^2\)` is that its magnitude depends in part on the magnitude of the other effects in the design. If the amount of variability due to Noise or Speed x Noise changes, so to does the effect size for Speed.

`$$\large \eta^2_{\text{speed}} = \frac{SS_{\text{speed}}}{SS_{\text{speed}} + SS_{\text{noise}} + SS_{\text{speed:noise}}+ SS_{\text{within}}}$$`

An alternative is to pretend the other effects do not exist and reference the effect sum of squares to residual variability.

`$$\large \text{partial }\eta^2_{\text{speed}} = \frac{SS_{\text{speed}}}{SS_{\text{speed}} + SS_{\text{within}}}$$`
---

### `\(\eta^2\)`

One rationale for partial `\(\eta^2\)` is that the residual variability represents the expected variability in the absence of any treatments or manipulations.  The presence of any treatments or manipulations only adds to total variability.  Viewed from that perspective, residual variability is a sensible benchmark against which to judge any effect.

`$$\large \text{partial }\eta^2_{\text{effect}} = \frac{SS_{\text{effect}}}{SS_{\text{effect}} + SS_{\text{within}}}$$`

Partial `\(\eta^2\)` is sometimes described as the expected effect size in a study in which the effect in question is the only effect present.

---

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Source &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; SS &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; `\(\eta^2\)` &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; `\(\text{partial }\eta^2\)` &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Speed &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2805871.4 &lt;/td&gt;
   &lt;td style="text-align:right;width: 10em; "&gt; 0.50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.56 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Noise &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 341315.2 &lt;/td&gt;
   &lt;td style="text-align:right;width: 10em; "&gt; 0.06 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.13 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Speed:Noise &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 295719.7 &lt;/td&gt;
   &lt;td style="text-align:right;width: 10em; "&gt; 0.05 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.12 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Residuals &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2192938.9 &lt;/td&gt;
   &lt;td style="text-align:right;width: 10em; "&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Total &lt;/td&gt;
   &lt;td style="text-align:right;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;width: 10em; "&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

Partial `\(\eta^2\)` will be larger than `\(\eta^2\)` if the ignored effects account for any variability.

The sum of partial `\(\eta^2\)` does not have a meaningful interpretation.

---
class: inverse

## Next Time

- Qualitative Methods: Dr. Amy Eyler
- Interactions IV (Power &amp; Effect size)
- Reminder: HW 3 is due 3/9
- Exam 2 will be on **April 2**
- Have a great spring break!


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
